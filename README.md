# Woltka

**Woltka**, or **W**eb **o**f **L**ife **T**ool**k**it **A**pp, is a collection of analytical tools for parsing. It means to interface between shotgun metagenomics (e.g., sequence aligners, taxonomic & functional profilers) and advanced analytical platforms (e.g., QIIME 2).

It currently provides the following functional modules (subcommands):

- **gotu**: gOTU table generation workflow.
- **classify**: Complete classification workflow with all parameters.

Woltka ships with a **QIIME 2 plugin**. [See here for instructions](woltka/q2).

## Contents

- [Installation](#installation)
- [Example usage](#example-usage)
- [gOTU analysis](#gotu-analysis)
- [Input files](#input-files)
- [Tree-based classification](#tree-based-classification)
- [Combined taxonomic & functional analyses](#combined-taxonomic--functional-analyses)


## Installation

Requires: Python 3.6 or above.

```bash
pip install git+https://github.com/qiyunzhu/woltka.git@dev
```

After installation, launch the program by executing:

```bash
woltka
```


## Example usage

Woltka ships with small test datasets under this directory:

```
<program_dir>/woltka/tests/data
```

One can execute the following commands to make sure that Woltka functions correctly, and to get an impression of the basic usage of Woltka.

gOTU table generation:

```bash
woltka gotu -i align/bowtie2 -o table.tsv
```

Taxonomic profiling at the ranks of phylum, genus and species as defined in NCBI taxdump:

```bash
woltka classify \
  -i align/bowtie2 \
  --nodes taxonomy/nodes.dmp \
  --names taxonomy/names.dmp \
  --rank phylum,genus,species \
  -o output_dir
```

Functional profiling by UniRef entries then by GO terms (molecular process):

```bash
woltka classify \
  -i align/bowtie2 \
  --coords function/coords.txt.xz \
  --map function/uniref.map.xz \
  --map function/go/process.tsv.xz \
  --rank uniref,process \
  -o output_dir
```


## gOTU analysis

**gOTU** is the more basic application implemented in Woltka. We will start with this simple analysis before diving into the complex and flexible usages.

### Background

The notion of “gOTU” (pronounced as "go-to") is the minimal unit for community ecology studies based on shotgun metagenome or other forms of whole-genome microbiome data. It is in constrast to conventional practices, in which taxonomic units such as genera or species were used. Therefore,  gOTU is analogous to sOTU in 16S rRNA studies. The advantage of using gOTU includes 1) highest-possible resolution, 2) independent from taxonomy which is coarse and error-prone as a classification system. 3) allowing for phylogeny-based analysis such as Faith’s PD and UniFrac. The last part is enhanced by the “web of life” reference phylogeny.

### gOTU table generation

To generate a gOTU table, one needs a directory of (only) alignment files, each representing one sample. These files can be generated by aligning sequencing data against a reference genome database. We recommend using [**SHOGUN**](https://github.com/knights-lab/SHOGUN) with the "Web of Life" database (**WoL**, available for download at: https://biocore.github.io/wol/):

```bash
shogun align -a bowtie2 -t 16 -d WoLr1 -i input.fasta -o align_dir
```

Then one can run Woltka to generate a gOTU table based on the alignment files.

```bash
woltka gotu -i align_dir -o table.tsv
```

The output file `table.tsv` is a table with rows as genome IDs (gOTUs), columns as sample IDs, and cell values as counts of gOTUs in samples.

Both SHOGUN and WoL are available from the [**Qiita**](https://qiita.ucsd.edu/) server.

### gOTU analysis using QIIME 2

With QIIME 2, the gOTU table can be converted into BIOM format:

```bash
biom convert --to-hdf5 -i table.tsv -o table.biom
```

The BIOM table can be imported into a QIIME 2 artifact:

```bash
qiime tools import --type FeatureTable[Frequency] --input-path table.biom --output-path table.qza
```

These intermediate steps are automated if you use the [QIIME 2 plugin of Woltka](woltka/q2).

One can then investigate the microbiome by applying classical QIIME 2 analyses on the gOTU table. For example, with the [WoL reference phylogeny](https://biocore.github.io/wol/), one can do:

```bash
qiime diversity core-metrics-phylogenetic \
  --i-phylogeny tree.qza \
  --i-table table.qza \
  --p-sampling-depth 1000 \
  --m-metadata-file metadata.tsv \
  --output-dir .
```

### Alignment ambiguity

It is quite common that one query sequence can be aligned to multiple reference genomes. In such cases, Woltka by default counts each gOTU as 1 / _k_, where _k_ is the total number of matching genomes.

Alternatively, one may choose to discard all non-unique matches, by adding a flag:

```bash
woltka gotu --no-multi ...
```

### Custom alignment

Technically, one can use any sequence aligners and reference genome databases to generate alignment files which can then be converted into a gOTU table. We cannot validate the goodness of outcome, but understand that you may have this intention considering the consistency with existing parts of your analytical pipeline. For examples:

```bash
bwa mem refseq.fna input.R1.fq input.R2.fq > output.sam
```

```bash
blastn -db refseq_genomes -query input.fa -max_target_seqs 1 -outfmt 6 -out output.txt
```

However, most of these protocols generate mappings of reads to nucleotides (e.g., chromosomes or scaffolds), rather than to genomes. In order to produce gOTUs, one needs to supply Woltka with a nucleotide-to-genome mapping file:

```bash
woltka gotu --map nucl2g.txt ...
```

### Final words

the `gotu` subcommand is actually a simplified wrapper of the full-power subcommand `classify`, which has more parameters to allow for extended features and controls, as detailed below.


## Input files

The input files for Woltka are sequence **alignment** files. The term "alignment" here describes the operation of aligning short sequencing reads against long reference sequences. The basic information an alignment file provides is the **mapping** between queries and subjects. In addition, the position and quality of alignments are available in some formats, which are useful in some applications.

Woltka supports the following alignment formats (specified by parameter `--format` or `-f`):

- `map`: Simple mapping of query \<tab\> subject.
- `sam`: SAM format. Supported by multiple tools such as Bowtie2 and BWA.
- `b6o`: BLAST tabular format (i.e., BLAST parameter `-outfmt 6`). Supported by multiple tools such as BLAST, DIAMOND, VSEARCH, BURST, etc.
- `auto` (default): Woltka will automatically infer the format of input alignment files.

Woltka supports and automatically detects common file compression formats including `gzip`, `bzip2` and `xz`.

In the default mode, Woltka treats every file under the directory specified by the `--input` or `-i` parameter as an alignment for one sample. The sample ID is automatically extracted from the filename, with filename extension stripped. Compression file extensions are automatically recognized. For example, the sample IDs for `S01.sam` and `S02.m8.gz` are `S01` and `S02`, respectively.

One may restrict this behavior to avoid confusions (e.g., there are unwanted files) by the following two parameters:

- `--extension` or `-e`: A suffix to be stripped from filenames, and the remaining part is considered a sample ID.

  For example, if valid alignment filenames have the pattern of `ID_L001.aln.bz2`, one may specify `-e _L001.aln.bz2`, so that only `ID` is retained, and filenames which do not have this suffix (e.g., `ID.bt2.log` or`readme.txt`) are ignored.

- `--sample-ids` or `-s`: A file containing valid sample IDs (one ID per line) to include in the current analysis. This list also specifies the order of sample IDs in the output profile.

  Only the first column before \<tab\> is considered. Lines starting with `#` are omitted. Therefore, a metadata table may also serve as a valid sample ID list.

Example of a complete command:

```bash
woltka classify \
  --input blast_output/ \
  --format b6o \
  --extension .blast6out.gz \
  --sample-ids ids.txt \
  --output profile.tsv \
  ...
```


## Tree-based classification

Woltka features a highly flexible hierarchical classification system. It is represented by a tree structure instead of a fixed number of levels (e.g., the eight standard taxonomic ranks). In another word, it is **rank-free**.

Wolkta supports various format of classification systems, specifically:

1. `--nodes`: NCBI-style `nodes.dmp` or compatible formats, in which each taxon is pointed to its parent taxon.

2. `--newick`: Newick-format tree, in which labels of tips and internal nodes are considered as taxa.

3. `--ranktb`: Tab-delimited table in which each column represents a rank.

4. `--lineage`: Map of taxon to lineage string, in the format of `taxonomic;units;from;high;to;low`. Can be Greengenes-style taxonomy where level codes such as `k__` will be parsed.
  - Compatible with QIIME, SHOGUN, MetaPhlAn2, GTDB, etc.

5. `--map`: One or multiple ordered maps of lower taxa to higher taxa. For example, the 1st file maps genes to UniRef entries, the 2nd maps UniRef entries to GO terms, the 3rd maps GO terms to GO slim terms, so on so forth.

6. If no classification file is provided, Woltka will automatically build a classification system from the mapping files, in which subject identifiers will be parsed as lineage strings.

These classification files are **additive**--unless they conflict--which will be noted by Woltka. For example:

```bash
woltka classify \
  --map nucl2g.txt \
  --map g2taxid.txt \
  --names taxdump/names.dmp \
  --nodes taxdump/nodes.dmp \
  ...
```

Again, compressed files are supported and automatically recognized. The following command works:

```bash
woltka classify --lineage gg_13_5_taxonomy.txt.gz ...
```


## Combined taxonomic & functional analyses

Woltka combines the two fundamental analyses in metagenomics: taxonomic profiling (mapping reads to genomes) and functional profiling (mapping reads to functional genes) into one run. This saves compute, ensures consistency, and allows for stratification which is essential for understanding functional diversity across the microbial community.

This is achieve by an efficient algorithm implemented in Woltka, which matches read alignments and annotated genes based on their coordinates on the host genome.

The coordinates of read-to-genome alignments are provided in the alignment files. One needs to provide Woltka with a table of gene coordinates. The format is like:

WoL reannotations (available for [download](https://biocore.github.io/wol/)):

```
>G000006745
1       806     372
2       2177    816
3       3896    2271
4       4446    4123
5       4629    4492
```

Native NCBI annotations and accessions:

```
## GCF_000005825.2
# NC_013791.2
WP_012957018.1  816 2168
WP_012957019.1  2348    3490
WP_012957020.1  3744    3959
WP_012957021.1  3971    5086
...
```

Again, compressed files are supported.

With the coordinates file, one can streamline the read-to-gene matching step into a Woltka protocol. Here is an example for functional profiling:

```bash
woltka classify \
  --coords coords.txt \
  --map gene2function.txt \
  --map function2pathway.txt \
  ...
```
